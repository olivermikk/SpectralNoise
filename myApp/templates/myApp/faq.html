{% extends 'base.html' %}
{% block content %}
<!-- css specific styling for faq page -->
<style>
  .accordion-button {
    font-size: 1.25rem; /* larger font */
    font-weight: 600;
    background-color: transparent !important;
    box-shadow: none !important;
    border: none !important;
    color: #222;
  }

  .accordion-button:focus {
    box-shadow: none;
  }

  .accordion-item {
    border: none;
    margin-bottom: 1rem;
  }

  .accordion-body {
    font-size: 0.95rem;
  }
</style>

<div class="container content-wrapper mt-4">
  <h1 class="mb-4">FAQ</h1>

  <!-- FAQ questions and answers -->
  <div class="accordion" id="faqAccordion">
    <!-- Q1 -->
    <div class="accordion-item">
      <h2 class="accordion-header" id="headingOne">
        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#faq1" aria-expanded="false" aria-controls="faq1">
          How are visuals created from the audio?
        </button>
      </h2>
      <div id="faq1" class="accordion-collapse collapse" aria-labelledby="headingOne" data-bs-parent="#faqAccordion">
        <div class="accordion-body">
          The live audio playback (either from microphone input or file playback) and the qualities of the audio are extracted and used as parameters to change the visual feedback.
        </div>
      </div>
    </div>

    <!-- Q2 -->
    <div class="accordion-item">
      <h2 class="accordion-header" id="headingTwo">
        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#faq2" aria-expanded="false" aria-controls="faq2">
          How is each element extracted from the audio?
        </button>
      </h2>
      <div id="faq2" class="accordion-collapse collapse" aria-labelledby="headingTwo" data-bs-parent="#faqAccordion">
        <div class="accordion-body">
          <p>When the audio is played the following properties are extracted using the p5.js library:</p>
          <ul>
            <li><strong>Amplitude</strong>: The overall loudness of the sound per frame.</li>
            <li><strong>Dominant Frequency</strong>: The frequency bin with the highest amplitude.</li>
            <li><strong>Frequency Spectrum</strong>: Averages amplitudes across frequency bins for tone-based visual control.</li>
          </ul>
          <p>All of these values are stored as global variables accessed by the visual generators to create responsive visuals.</p>
        </div>
      </div>
    </div>

    <!-- Q3 -->
    <div class="accordion-item">
      <h2 class="accordion-header" id="headingThree">
        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#faq3" aria-expanded="false" aria-controls="faq3">
          What is used to generate visuals from the audio?
        </button>
      </h2>
      <div id="faq3" class="accordion-collapse collapse" aria-labelledby="headingThree" data-bs-parent="#faqAccordion">
        <div class="accordion-body">
          A JavaScript Library is used called p5.js. p5.js is used for creative coding, providing tools to aid in the process of creating generative art.
        </div>
      </div>
    </div>

    <!-- Q4 -->
    <div class="accordion-item">
      <h2 class="accordion-header" id="headingFour">
        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#faq4" aria-expanded="false" aria-controls="faq4">
          What audio inputs does the visualizer support?
        </button>
      </h2>
      <div id="faq4" class="accordion-collapse collapse" aria-labelledby="headingFour" data-bs-parent="#faqAccordion">
        <div class="accordion-body">
          Either live audio input using a microphone input or audio file upload (mp3 or WAV files) can be used to generate the visual feedback.
        </div>
      </div>
    </div>

      <!-- Q5 -->
    <div class="accordion-item">
      <h2 class="accordion-header" id="headingFive">
        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#faq5" aria-expanded="false" aria-controls="faq4">
            Can I sync the visuals with my DAW (Ableton, Logic, etc.)?
        </button>
      </h2>
      <div id="faq5" class="accordion-collapse collapse" aria-labelledby="headingFive" data-bs-parent="#faqAccordion">
        <div class="accordion-body">
        While direct sync isnâ€™t supported yet, you can route your DAW audio to your system's input using software like Loopback, VB-Cable, or BlackHole to feed it into the visualizer.

        </div>
      </div>
    </div>


      <!-- Q6 -->
    <div class="accordion-item">
      <h2 class="accordion-header" id="headingSix">
        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#faq6" aria-expanded="false" aria-controls="faq4">
        Can I create my own visual algorithms?
        </button>
      </h2>
      <div id="faq6" class="accordion-collapse collapse" aria-labelledby="headingSix" data-bs-parent="#faqAccordion">
        <div class="accordion-body">
        The current version of Spectral Noise does not allow for your own creative coding visualizations to be
            implemented into the web application. Although a sandbox environment for designing your own visual generators
            is in development, allowing to drag and drop certain elements to make combinations of interactive visual responses.

        </div>
      </div>
    </div>

  </div>
</div>
{% endblock %}
